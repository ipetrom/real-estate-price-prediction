{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "This script is used to search for and download data on studios from otodom.pl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import StaleElementReferenceException, ElementClickInterceptedException, NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium configuration\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")  # Maximize the browser window\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Bypass automation detection\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])  # Prevent automation detection\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)  # Disable automation extension\n",
    "\n",
    "\n",
    "# Path to CSV file\n",
    "CSV_PATH = \"otodom_studio_offers.csv\" # Define the path for the CSV file\n",
    "\n",
    "# Base URL\n",
    "BASE_URL = \"https://www.otodom.pl/pl/wyniki/sprzedaz/kawalerka/cala-polska\"  # Define the base URL for scraping\n",
    "\n",
    "# Close cookies pop-up\n",
    "def close_cookies_popup(driver):\n",
    "    try:\n",
    "        cookie_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\"))  # Wait for the cookie accept button\n",
    "        )\n",
    "        cookie_button.click()  # Click the cookie accept button\n",
    "        print(\"Cookies pop-up closed.\")\n",
    "        time.sleep(2)  # Allow time for the pop-up to close\n",
    "    except TimeoutException:\n",
    "        print(\"No cookies pop-up to close.\")\n",
    "\n",
    "# Expand building details section\n",
    "def expand_building_details(driver):\n",
    "    try:\n",
    "        header = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//header[p[contains(text(), \"Budynek i materiały\")]]')) # Wait for the \"Building and materials\" section\n",
    "        )\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", header)  # Scroll to the header\n",
    "        time.sleep(1)\n",
    "        header.click()  # Click the header to expand\n",
    "        time.sleep(2)\n",
    "        \n",
    "        details_section = driver.find_elements(By.XPATH, '//div[contains(@class, \"css-1ftuvmu\") and not(@hidden)]')  # Check if details are visible\n",
    "        if details_section:\n",
    "            print(\"Building and materials section expanded!\")\n",
    "        else:\n",
    "            print(\"Selenium still can't see the section!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Get value after a given label\n",
    "def get_value_after_label(label, driver):\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, f'//p[text()=\"{label}\"]/following-sibling::p')  # Find the value after the label\n",
    "        return element.text.strip()\n",
    "    except NoSuchElementException:\n",
    "        return \"Brak danych\"  # Return \"Brak danych\" if element is not found\n",
    "\n",
    "# Get value from details section, retrying if necessary\n",
    "def get_value_from_details(label, driver):\n",
    "    try:\n",
    "        time.sleep(2) \n",
    "\n",
    "        elements = driver.find_elements(By.XPATH, f'//p[contains(text(), \"{label}\")]/following-sibling::p') # Locate the detail value\n",
    "        if elements:\n",
    "            return elements[0].text.strip()\n",
    "        else:\n",
    "            print(f\"Selenium don't found '{label}'\")\n",
    "            return \"Brak danych\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error during downloading '{label}': {e}\")\n",
    "        return \"Brak danych\"\n",
    "\n",
    "\n",
    "# Get value from button elements\n",
    "def get_value_from_buttons(index, driver):\n",
    "    try:\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, 'button.eezlw8k1.css-1nk40gi')  # Find all buttons\n",
    "        if len(buttons) > index:\n",
    "            return buttons[index].find_element(By.CSS_SELECTOR, 'div.css-1ftqasz').text.strip()  # Extract text\n",
    "        return \"Brak danych\"\n",
    "    except NoSuchElementException:\n",
    "        return \"Brak danych\"\n",
    "\n",
    "# Retrieve offer links\n",
    "def get_offer_links(driver, max_links=1000):\n",
    "    driver.get(BASE_URL)  # Open the base URL\n",
    "    wait = WebDriverWait(driver, 15)  # Set an explicit wait time  \n",
    "\n",
    "    close_cookies_popup(driver)  # Close cookies pop-up\n",
    "\n",
    "    all_links = set()\n",
    "    previous_links = set() \n",
    "\n",
    "    while len(all_links) < max_links:\n",
    "        try:\n",
    "            offers = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a[href^=\"/pl/oferta/\"]')))  # Find all offer links\n",
    "            new_links = {offer.get_attribute('href') for offer in offers if offer.get_attribute('href')}  # Extract href attributes\n",
    "            \n",
    "            # Checking that the site has actually changed\n",
    "            if new_links == previous_links:\n",
    "                print(\"Page did not update offers. Retrying...\")\n",
    "                time.sleep(3)\n",
    "                continue  # Repeat the download attempt\n",
    "\n",
    "            previous_links = new_links  # Updating previous links\n",
    "            all_links.update(new_links)\n",
    "            print(f\"Retrieved {len(new_links)} new offers, total: {len(all_links)}\")\n",
    "\n",
    "            # Checking the offer limit\n",
    "            if len(all_links) >= max_links:\n",
    "                print(\"Offer limit reached, stopping link collection.\")\n",
    "                break\n",
    "\n",
    "            # Scroll to the ‘Next page’ button\n",
    "            try:\n",
    "                next_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//li[@title=\"Go to next Page\" and @aria-disabled=\"false\"]')))  # Locate pagination button\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)  # Scroll to button\n",
    "                time.sleep(random.uniform(1, 2))\n",
    "\n",
    "                # Re-attempting to click\n",
    "                attempts = 0\n",
    "                while attempts < 3:\n",
    "                    try:\n",
    "                        next_button.click()\n",
    "                        time.sleep(random.uniform(4, 6))  # Longer waiting time for loading\n",
    "                        break\n",
    "                    except ElementClickInterceptedException:\n",
    "                        print(\"Click failed, retrying...\")\n",
    "                        driver.execute_script(\"arguments[0].click();\", next_button)  # Force click via JS\n",
    "                        time.sleep(1)\n",
    "                        attempts += 1\n",
    "\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                print(\"Pagination button not found. Ending link collection.\")\n",
    "                break\n",
    "            \n",
    "        except StaleElementReferenceException:\n",
    "            print(\"Page updated, retrying...\")\n",
    "            continue\n",
    "\n",
    "    return list(all_links)[:max_links]   \n",
    "\n",
    "# Downloading offer details\n",
    "def get_offer_details(offer_url, driver):\n",
    "    driver.get(offer_url)  # Open the offer URL\n",
    "    time.sleep(random.uniform(2, 4))  # Wait for the page to load\n",
    "\n",
    "    data = {\"URL\": offer_url}  # Initialize data dictionary\n",
    "\n",
    "    def get_text(selector, driver):\n",
    "        try:\n",
    "            return driver.find_element(By.CSS_SELECTOR, selector).text.strip()  # Extract text from given selector\n",
    "        except:\n",
    "            return \"Brak danych\"\n",
    "\n",
    "    # Extracting offer details\n",
    "    data[\"Cena\"] = get_text('strong[data-cy=\"adPageHeaderPrice\"]', driver)\n",
    "    data[\"Cena za m²\"] = get_text('div[aria-label=\"Cena za metr kwadratowy\"]', driver)\n",
    "    data[\"Adres\"] = get_text('a.css-1jjm9oe', driver)\n",
    "    data[\"Powierzchnia (m²)\"] = get_value_from_buttons(0, driver)\n",
    "    data[\"Liczba pokoi\"] = get_value_from_buttons(1, driver)\n",
    "    data[\"Ogrzewanie\"] = get_value_after_label(\"Ogrzewanie\", driver)\n",
    "    data[\"Rynek\"] = get_value_after_label(\"Rynek\", driver)\n",
    "    data[\"Typ ogłoszeniodawcy\"] = get_value_after_label(\"Typ ogłoszeniodawcy\", driver)\n",
    "\n",
    "    expand_building_details(driver)  # Expand additional building details\n",
    "    time.sleep(15)  # Wait for details to load\n",
    "    data[\"Rok budowy\"] = get_value_from_details(\"Rok budowy\", driver)\n",
    "    time.sleep(5)\n",
    "    data[\"Rodzaj zabudowy\"] = get_value_from_details(\"Rodzaj zabudowy\", driver)\n",
    "    time.sleep(5)\n",
    "    data[\"Okna\"] = get_value_from_details(\"Okna\", driver)\n",
    "    time.sleep(5)\n",
    "    data[\"Materiał budynku\"] = get_value_from_details(\"Materiał budynku\", driver)\n",
    "\n",
    "    print(\"\\n Oferta pobrana:\")\n",
    "    for key, value in data.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Scrape Otodom webpage\n",
    "def scrape_otodom(offer_links, driver):\n",
    "    all_data = []  # Initialize an empty list to store the scraped data\n",
    "\n",
    "    # Loop through each offer link, using enumerate to track the index and link\n",
    "    for idx, link in enumerate(offer_links, 1):\n",
    "        print(f\"\\n Downloading offer number {idx}: {link}\") \n",
    "        details = get_offer_details(link, driver)  # Get the offer details using the provided link and driver\n",
    "        all_data.append(details)  \n",
    "        time.sleep(random.uniform(2, 5))  \n",
    "\n",
    "    save_to_csv(all_data)  # Save the collected data to a CSV file\n",
    "\n",
    "# Save data to CSV\n",
    "def save_to_csv(data):\n",
    "    keys = data[0].keys() if data else []  # Get the keys from the first dictionary in the data list (column names)\n",
    "\n",
    "    # Open the CSV file at the given path (CSV_PATH) in write mode\n",
    "    with open(CSV_PATH, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=keys) \n",
    "        writer.writeheader()  # Write the header (column names) to the CSV file\n",
    "        writer.writerows(data)  \n",
    "    print(f\"\\n Data saved to file: {CSV_PATH}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver instance\n",
    "driver = webdriver.Chrome(service=service, options=options)  # Start the Chrome browser with specified options\n",
    "offer_links = get_offer_links(driver)  # Retrieve offer links from the target website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_otodom(offer_links, driver)  # Start scraping offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()  # Close the browser and end the WebDriver session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
